{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from DLBio import pt_training\n",
    "import ds_ear\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "import torch.nn as nn\n",
    "from DLBio.pytorch_helpers import get_device, get_num_params\n",
    "from DLBio.helpers import check_mkdir\n",
    "from DLBio.pt_train_printer import Printer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(pt_training.ITrainInterface):\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.xent_loss = nn.CrossEntropyLoss()\n",
    "        self.metrics = {\n",
    "            'acc': accuracy\n",
    "        }\n",
    "        self.d = device\n",
    "\n",
    "    def train_step(self, sample):\n",
    "        images, targets = sample[0].to(self.d), sample[1].to(self.d)\n",
    "        pred = self.model(images)\n",
    "\n",
    "        loss = self.xent_loss(pred, targets)\n",
    "        metrics = dict()\n",
    "\n",
    "        metrics.update({k: v(pred, targets) for k, v in self.metrics.items()})\n",
    "\n",
    "        return loss, metrics\n",
    "\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    _, y_pred = y_pred.max(1)  # grab class predictions\n",
    "    return (y_pred == y_true).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants\n",
    "FOLDER = './class_sample'\n",
    "OPT_TYPE = 'Adam'\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0.000001\n",
    "EPOCHS = 10\n",
    "LR_STEPS = 3\n",
    "DO_EARLY_STOPPING = True\n",
    "STOP_AFTER = 10\n",
    "ES_METRIC = 'val_acc'\n",
    "SAVE_INTERVALL = -1\n",
    "PRINT_FREQUENCY = 500 # print every 500 batches\n",
    "SEED = 0\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "# use seeds to ensure comparable results ()\n",
    "# pt_training.set_random_seed(SEED)\n",
    "\n",
    "# apply to device\n",
    "device = get_device()\n",
    "print(device)\n",
    "model = mobilenet_v2(pretrained=True)\n",
    "\n",
    "# model.classifier = nn.Sequential(\n",
    "#    nn.Dropout(p=0.2, inplace=False),\n",
    "#    nn.Linear(in_features=1280, out_features=2, bias=True)\n",
    "# )\n",
    "model.classifier.add_module(\"2\", nn.Linear(1000, 2))\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# definde folder to save model and log file\n",
    "check_mkdir(FOLDER, is_dir=True)\n",
    "model_out = join(FOLDER, 'model.pt')\n",
    "log_file = join(FOLDER, 'log.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write some model specs\n",
    "with open(join(FOLDER, 'model_specs.json'), 'w') as file:\n",
    "    json.dump({\n",
    "        'num_trainable': float(get_num_params(model, True)),\n",
    "        'num_params': float(get_num_params(model, False))\n",
    "    }, file)\n",
    "\n",
    "# define indicies to split Data\n",
    "N = len(ds_ear.get_dataset())\n",
    "n_80 = int(.8*N)\n",
    "n_60 = int(.6*N)\n",
    "n_20 = int(.2*N)\n",
    "\n",
    "rand_indeces = np.random.permutation(N)\n",
    "train_indeces = rand_indeces[:n_80]\n",
    "valid_indeces = rand_indeces[n_80:]\n",
    "#valid_indeces = rand_indeces[n_60:n_60+n_20]\n",
    "#test_indeces = rand_indeces[n_60+n_20:]\n",
    "\n",
    "# definde data loader\n",
    "dl_train = ds_ear.get_dataloader(\n",
    "    indeces=train_indeces,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "dl_valid = ds_ear.get_dataloader(\n",
    "    indeces=valid_indeces,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "# dl_test = ds_ear.get_dataloader(\n",
    "#     indeces=test_indeces,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     num_workers=NUM_WORKERS,\n",
    "#     is_train=False\n",
    "# )\n",
    "\n",
    "# with open('test_indizes.txt', 'w') as file:\n",
    "#     for idx in test_indeces:\n",
    "#         file.write(\"%i\\n\" % idx)\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "optimizer = pt_training.get_optimizer(\n",
    "        'Adam', model.parameters(),\n",
    "        LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "if LR_STEPS > 0:\n",
    "    scheduler = pt_training.get_scheduler(\n",
    "            LR_STEPS, EPOCHS, optimizer)\n",
    "\n",
    "if DO_EARLY_STOPPING:\n",
    "    assert SAVE_INTERVALL == -1\n",
    "    early_stopping = pt_training.EarlyStopping(\n",
    "            ES_METRIC, get_max=True, epoch_thres=STOP_AFTER\n",
    "        )\n",
    "else:\n",
    "    early_stopping = None\n",
    "    \n",
    "train_interface = Classification(model, device)\n",
    "\n",
    "training = pt_training.Training(\n",
    "        optimizer, dl_train, train_interface,\n",
    "        scheduler=scheduler, printer=Printer(PRINT_FREQUENCY, log_file),\n",
    "        save_path=model_out, save_steps=SAVE_INTERVALL,\n",
    "        val_data_loader=dl_valid,\n",
    "        early_stopping=early_stopping\n",
    "    )\n",
    "\n",
    "training(EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_file, 'r') as file:\n",
    "    log = json.load(file)\n",
    "\n",
    "plt.plot(log['acc'], label='acc')\n",
    "plt.plot(log['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenvfe65d2ae6af74790a8c3d2ed63037c92",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}