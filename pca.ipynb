{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.8 64-bit ('ear')",
   "display_name": "Python 3.6.8 64-bit ('ear')",
   "metadata": {
    "interpreter": {
     "hash": "c2e483ab6d2869a436ac078172a85a5d29909efb0d20a1467c5a44ad2f46e474"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib._color_data as mcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = './embeddings/radius_2.0'\n",
    "emb_list = listdir(emb_dir)\n",
    "emb_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, labels = [], []\n",
    "for label in emb_list:\n",
    "    loaded = np.load(join(emb_dir,label), allow_pickle=True)\n",
    "\n",
    "    for e in loaded:\n",
    "        vectors.append(e.detach().numpy()[0])\n",
    "        labels.append(label[:-4])\n",
    "\n",
    "x = np.asarray(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Untouched:\t  0.50067055 \t 0.073979214\nNormalized:\t  -1.0525927e-08 \t 1.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3760, 1280)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Normalize Data\n",
    "x_norm = StandardScaler().fit_transform(x) # normalizing the features\n",
    "\n",
    "print('Untouched:\\t ', np.mean(x),'\\t', np.std(x))\n",
    "print('Normalized:\\t ', np.mean(x_norm),'\\t', np.std(x_norm))\n",
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Component 1  Component 2  Component 3\n",
       "alexander_bec    -2.897444    -8.432858    12.079668\n",
       "alexander_bec    -7.278646    -5.762889    12.076149\n",
       "alexander_bec    -4.215930   -11.224479    10.930253\n",
       "alexander_bec    -6.226907    -5.715588    12.380111\n",
       "alexander_bec     1.519285    -8.938177     2.300370"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Component 1</th>\n      <th>Component 2</th>\n      <th>Component 3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alexander_bec</th>\n      <td>-2.897444</td>\n      <td>-8.432858</td>\n      <td>12.079668</td>\n    </tr>\n    <tr>\n      <th>alexander_bec</th>\n      <td>-7.278646</td>\n      <td>-5.762889</td>\n      <td>12.076149</td>\n    </tr>\n    <tr>\n      <th>alexander_bec</th>\n      <td>-4.215930</td>\n      <td>-11.224479</td>\n      <td>10.930253</td>\n    </tr>\n    <tr>\n      <th>alexander_bec</th>\n      <td>-6.226907</td>\n      <td>-5.715588</td>\n      <td>12.380111</td>\n    </tr>\n    <tr>\n      <th>alexander_bec</th>\n      <td>1.519285</td>\n      <td>-8.938177</td>\n      <td>2.300370</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components=3)\n",
    "components_ear = pca.fit_transform(x_norm)\n",
    "\n",
    "ear_df = pd.DataFrame(data = components_ear, index = labels, columns = ['Component 1', 'Component 2', 'Component 3'],)\n",
    "\n",
    "\n",
    "ear_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Explained variation per principal component: [0.42371824 0.29322845 0.2630762 ]\nTotal variance explained: 0.9800228774547577\n"
     ]
    }
   ],
   "source": [
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "print('Total variance explained: {}'.format(sum(pca.explained_variance_ratio_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for creating colors\n",
    "ear_df['label'] = pd.Categorical(labels)\n",
    "# my_color = ear_df['label'].cat.codes\n",
    "# ear_df = ear_df.drop('persons', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(labels))\n",
    "unique.sort()\n",
    "\n",
    "pseudonyms = dict()\n",
    "for i, proband in enumerate(unique):\n",
    "    pseudonyms[proband] = \"Proband_\"+str(i+1)\n",
    "\n",
    "cluster_center = dict()\n",
    "for person in unique:\n",
    "    cluster_center[person] = (sum(ear_df.loc[person, 'Component 1'])/80, sum(ear_df.loc[person, 'Component 2'])/80, sum(ear_df.loc[person, 'Component 3'])/80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "alexander_bec \t--\t Proband_1\nalina_sch \t--\t Proband_2\nalissa_buh \t--\t Proband_3\namanda_dab \t--\t Proband_4\nanna_kab \t--\t Proband_5\nanni_qua \t--\t Proband_6\nbeatrix_mah \t--\t Proband_7\nclara_pau \t--\t Proband_8\nclemens_blu \t--\t Proband_9\ncollin_sch \t--\t Proband_10\ndavid_fau \t--\t Proband_11\nfalco_len \t--\t Proband_12\nfelix_mec \t--\t Proband_13\ngregor_spi \t--\t Proband_14\nhammam_als \t--\t Proband_15\njanna_qua \t--\t Proband_16\njanole_pen \t--\t Proband_17\njesse_kru \t--\t Proband_18\njohannes_wie \t--\t Proband_19\njule_dre \t--\t Proband_20\njulia_fis \t--\t Proband_21\nkonrad_von \t--\t Proband_22\nlars_fin \t--\t Proband_23\nlinus_fal \t--\t Proband_24\nlynn_man \t--\t Proband_25\nmaike_her \t--\t Proband_26\nmalte_gas \t--\t Proband_27\nmarcel_nim \t--\t Proband_28\nmarcus_jue \t--\t Proband_29\nmarejke_wen \t--\t Proband_30\nmarina_fri \t--\t Proband_31\nmarina_han \t--\t Proband_32\nmatilda_kni \t--\t Proband_33\nmeiko_pri \t--\t Proband_34\nmila_wol \t--\t Proband_35\nmohammed_muh \t--\t Proband_36\nmoritz_bor \t--\t Proband_37\nmoritz_mei \t--\t Proband_38\nnils_loo \t--\t Proband_39\npauline_bus \t--\t Proband_40\nrobert_kle \t--\t Proband_41\nrobert_sch \t--\t Proband_42\nsarah_amo \t--\t Proband_43\nsarah_feh \t--\t Proband_44\nsina_jun \t--\t Proband_45\ntim_moe \t--\t Proband_46\nyannik_obe \t--\t Proband_47\n"
     ]
    }
   ],
   "source": [
    "for i in pseudonyms:\n",
    "    print(i, '\\t--\\t', pseudonyms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## DEFINE X- and Y- AXIS\n",
    "x_component = 1\n",
    "y_component = 3\n",
    "assert x_component >= 1 and x_component <=3 and y_component >= 1 and y_component <=3\n",
    "# Plot preparations\n",
    "fig = plt.figure(figsize = (30,30))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component ' + str(x_component), fontsize = 15)\n",
    "ax.set_ylabel('Principal Component ' + str(y_component), fontsize = 15)\n",
    "ax.set_title('PCA of ear embeddings - 2 of three dimensions ', fontsize = 20)\n",
    "targets = unique\n",
    "colors = list(mcd.XKCD_COLORS.values())\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = ear_df['label'] == target\n",
    "    # ax.scatter(x=cluster_center[target][0], y=cluster_center[target][1], s=5, c='red', marker='*')\n",
    "    ax.scatter(ear_df.loc[indicesToKeep, 'Component ' + str(x_component)]\n",
    "               , ear_df.loc[indicesToKeep, 'Component ' + str(y_component)]\n",
    "               , c = color\n",
    "               , s = 15\n",
    "               , alpha=0.6)\n",
    "\n",
    "# SWITCH annotations and legend respectively if pseudonyms are wanted\n",
    "    ax.annotate(s=pseudonyms[target], xy=(cluster_center[target][x_component-1], cluster_center[target][y_component-1]), textcoords='data' )\n",
    "    # ax.annotate(s=target, xy=(cluster_center[target][x_component-1], cluster_center[target][y_component-1]), textcoords='data' )\n",
    "ax.legend(pseudonyms.values())\n",
    "# ax.legend(targets)\n",
    "\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_component(dictionary, component, reverse=False):\n",
    "    '''Function to sort the cluster center dictionary by the component\n",
    "    Arguments\n",
    "    ----------\n",
    "    component: 1, 2 or 3 representing the 3 dimensions\n",
    "    reverse: default is false, returning an ascending order\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    sorted_reduced: a list containing the tuples of (key, component) of specified component\n",
    "    '''\n",
    "\n",
    "    assert component>=1 and component<=3\n",
    "    # change to array space\n",
    "    component -= 1\n",
    "\n",
    "    sorted_values = sorted(dictionary.items(), key=lambda x: x[1][component], reverse=reverse)\n",
    "\n",
    "    sorted_reduced = [(label, values[component]) for (label, values) in sorted_values]\n",
    "    return sorted_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "These are the values of the component  3 \n\n          Proband_33 : -33.52497308254242\n          Proband_14 : -32.77197790145874\n           Proband_3 : -29.932307505607604\n           Proband_8 : -25.84393093585968\n          Proband_39 : -22.9295375585556\n           Proband_4 : -21.152161049842835\n          Proband_46 : -19.94115219116211\n          Proband_43 : -17.71762643456459\n          Proband_30 : -16.83368911743164\n          Proband_18 : -16.832468223571777\n          Proband_20 : -15.230828738212585\n           Proband_2 : -13.690478479862213\n          Proband_34 : -12.422663629055023\n          Proband_37 : -11.864496368169785\n          Proband_16 : -10.628432929515839\n          Proband_12 : -10.58404398560524\n           Proband_7 : -7.377546975761652\n          Proband_21 : -6.1434707075357435\n          Proband_47 : -5.9656054601073265\n          Proband_15 : -5.744850511848926\n           Proband_6 : -4.964224353432655\n          Proband_25 : -4.415202879905701\n          Proband_26 : -4.007421664893627\n          Proband_36 : -3.7571602926589547\n          Proband_27 : 0.40060765906237067\n          Proband_45 : 1.5982010571518912\n          Proband_35 : 1.914491805061698\n          Proband_19 : 2.944658659165725\n          Proband_40 : 3.1504551930527667\n           Proband_5 : 4.042270801542327\n          Proband_41 : 4.617124856263399\n          Proband_22 : 6.376811191439629\n           Proband_1 : 10.917792685329914\n          Proband_23 : 12.265259808301925\n          Proband_32 : 12.30232743024826\n          Proband_13 : 15.301293694972992\n          Proband_42 : 16.096657371520998\n           Proband_9 : 18.781648290157317\n          Proband_38 : 19.175983929634093\n          Proband_17 : 22.274121391773225\n          Proband_24 : 22.620071125030517\n          Proband_31 : 23.211095142364503\n          Proband_10 : 24.451414036750794\n          Proband_44 : 26.22768292427063\n          Proband_29 : 29.570875930786134\n          Proband_11 : 36.033337879180905\n          Proband_28 : 40.00206580162048\n"
     ]
    }
   ],
   "source": [
    "## Set component 1, 2 or 3\n",
    "c = 3\n",
    "\n",
    "sort_values = sort_dict_by_component(cluster_center, c)\n",
    "print('These are the values of the component ', c, '\\n')\n",
    "for l,v in sort_values:\n",
    "    # SWITCH respectively if pseudonyms are wanted\n",
    "    print('{:>20} : {:<}'.format(pseudonyms[l],v))\n",
    "    # print('{:>20} : {:<}'.format(l,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average step size\t:  1.5984138887861499\nMedian of step size\t:  1.2225425634533162\n[0.0012208938598625707, 0.03706762194633484, 0.04438894391059911, 0.17786524742841703, 0.20579653388704156, 0.22075494825840014, 0.2502613722346725, 0.3162907479098067, 0.3459497332572923, 0.3943356394767754, 0.40778121501207387, 0.5490214735269543, 0.5581672608852379, 0.5748540547210723, 0.5910240173339858, 0.7529951810836764, 0.780626158416271, 0.7953636765480052, 0.8839373171329505, 0.8918156084895603, 1.0301668541040272, 1.1975933980895206, 1.2110088586807244, 1.234076268225908, 1.2360634386539466, 1.2403188943862915, 1.2678148508071896, 1.3474671229720112, 1.5403502583503723, 1.6016394853591915, 1.7596863351762293, 1.7762688875198371, 1.7773765087127664, 2.223525756597521, 2.68499091863632, 2.8396703958511367, 2.91439337730408, 2.998966264724732, 3.0981374621391318, 3.206497009843588, 3.343193006515502, 3.9687279224395766, 4.088376569747922, 4.1577679517213255, 4.5409814938902855, 6.462461948394772]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "val = [v for _,v in sort_values]\n",
    "steps = []\n",
    "for i in range(len(val)-1):\n",
    "    steps.append(abs(val[i]-val[i+1]))\n",
    "\n",
    "steps.sort()\n",
    "\n",
    "print('Average step size\\t: ', np.mean(steps))\n",
    "print('Median of step size\\t: ', np.median(steps))\n",
    "steps_int = [int(x) for x in steps]\n",
    "print(steps)\n",
    "print(steps_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "115.08344720496895"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageStat\n",
    "import PIL\n",
    "def brightness( im_file ):\n",
    "   im = Image.open(im_file)\n",
    "   stat = ImageStat.Stat(im)\n",
    "   return stat.mean[0]\n",
    "\n",
    "brightness('../samples/fusion2040_gray/konrad_von.png')\n",
    "# def add(a, b):\n",
    "#     return a+b\n",
    "\n",
    "# hist_positive = list(np.zeros(255))\n",
    "\n",
    "# d = Image.open('../samples/fusion2040_gray/konrad_von.png')\n",
    "# hist_positive = list( map(add, hist_positive, d.histogram()) )\n",
    "# hist_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16  \"Negative\" Images\nNegative Value Images Mean brightness\t:  102.13541052018635\nNegative Value Images RMS brightness\t:  108.73903037322536 \n\n15  \"Positive\" Images\nPositive Value Images Mean brightness\t:  106.85719358178054\nPositive Value Images RMS brightness\t:  112.02845810404907\n73.76187888198758\n94.4145652173913\n64.28358695652175\n79.5810248447205\n105.5138354037267\n111.57551242236025\n113.11277950310559\n136.88402173913045\n93.17798136645963\n101.28855590062112\n100.7179347826087\n96.1641149068323\n125.93472049689441\n103.83360248447205\n94.68857142857142\n139.23388198757763\n104.8139596273292\n99.35299689440994\n129.7648602484472\n105.92031055900621\n113.42054347826087\n109.9758850931677\n105.9346894409938\n132.34391304347827\n99.3858850931677\n115.65122670807453\n101.30777950310559\n106.70130434782608\n103.5724844720497\n92.67478260869565\n113.94495341614906\n115.08344720496895\n92.48563664596273\n103.44155279503106\n108.05318322981367\n99.32218944099378\n98.695\n101.22108695652175\n111.1398602484472\n104.79863354037268\n98.8829347826087\n143.36667701863354\n100.96464285714286\n105.80012422360248\n122.82116459627329\n110.65857142857143\n101.20664596273292\n\n Amount of direct increments\t:  23\n"
     ]
    }
   ],
   "source": [
    "# Extract histograms of certain images\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from PIL import ImageStat\n",
    "\n",
    "def brightness_and_rms( im_file ):\n",
    "   im = Image.open(im_file)\n",
    "   stat = ImageStat.Stat(im)\n",
    "   return stat.mean[0], stat.rms[0]\n",
    "\n",
    "path_to_grayscale = '../samples/fusion2040_gray'\n",
    "\n",
    "av_bright_negative, rms_bright_neg = 0, 0\n",
    "neg_count = 0\n",
    "av_bright_positive, rms_bright_pos = 0, 0\n",
    "pos_count = 0\n",
    "\n",
    "# SET COMPONENT 1,2 or 3\n",
    "c = 3\n",
    "val_thresh = 10\n",
    "# Above, cluster_center is created, containing the people and their component's center value\n",
    "# We will have a look at the histogram of all greyscale images above compared to the images with a component value below zero\n",
    "for person in cluster_center:\n",
    "    val = cluster_center[person][c-1]\n",
    "    val_bright, val_bright_rms = brightness_and_rms(join(path_to_grayscale, person+'.png'))\n",
    "    if val < -val_thresh:\n",
    "        av_bright_negative += val_bright\n",
    "        rms_bright_neg += val_bright_rms\n",
    "        neg_count += 1\n",
    "    elif val > val_thresh:\n",
    "        av_bright_positive += val_bright\n",
    "        rms_bright_pos += val_bright_rms\n",
    "        pos_count +=1\n",
    "\n",
    "print(neg_count, ' \"Negative\" Images')\n",
    "print('Negative Value Images Mean brightness\\t: ', av_bright_negative/neg_count)\n",
    "print('Negative Value Images RMS brightness\\t: ', rms_bright_neg/neg_count, '\\n')\n",
    "print(pos_count, ' \"Positive\" Images')\n",
    "print('Positive Value Images Mean brightness\\t: ', av_bright_positive/pos_count)\n",
    "print('Positive Value Images RMS brightness\\t: ', rms_bright_pos/pos_count)\n",
    "\n",
    "count = -1\n",
    "temp = 0\n",
    "for person,_ in sort_values:\n",
    "    val_bright, val_bright_rms = brightness_and_rms(join(path_to_grayscale, person+'.png'))\n",
    "    print(val_bright)\n",
    "    if val_bright > temp:\n",
    "        count += 1\n",
    "    temp = val_bright\n",
    "print('\\n', 'Amount of direct increments\\t: ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}