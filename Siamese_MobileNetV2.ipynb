{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch import cuda\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from siamese_network_dataset import SiameseNetworkDataset\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "from ContrastiveLossFunction import ContrastiveLoss\n",
    "from DLBio.pytorch_helpers import get_device, get_num_params\n",
    "from DLBio.helpers import check_mkdir\n",
    "from os.path import join\n",
    "from siamese_network_train import Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up All Configurations here\n",
    "class Config():\n",
    "    training_dir = \"../data/ears/training/\"\n",
    "    testing_dir = \"../data/ears/testing/\"\n",
    "    train_batch_size = 32\n",
    "    \n",
    "    EPOCHS= 10\n",
    "    LEARNINGRATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       ,should_invert=False)\n",
    "\n",
    "train_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=Config.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(siamese_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=8)\n",
    "dataiter = iter(vis_dataloader)\n",
    "\n",
    "example_batch = next(dataiter)\n",
    "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                        transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ])\n",
    "                                       ,should_invert=False)\n",
    "\n",
    "test_dataloader = DataLoader(siamese_dataset,num_workers=6,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definde Model and load to device\n",
    "model = mobilenet_v2(pretrained=True)\n",
    "model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=10)\n",
    "\n",
    "device = get_device()\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "contrastiv_loss_siamese = ContrastiveLoss()\n",
    "optimizer_siamese = optim.Adam(model.parameters(),lr = Config.LEARNINGRATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training a Siamese Model based on dissimilarity\n",
    "training = Training(model=model, optimizer=optimizer_siamese,train_dataloader=train_dataloader, \n",
    "                loss_contrastive=contrastiv_loss_siamese)\n",
    "\n",
    "counter, loss_history = training(Config.EPOCHS)\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataiter = iter(test_dataloader)\n",
    "x0,_,_ = next(dataiter)\n",
    "\n",
    "for i in range(10):\n",
    "    _,x1,label2 = next(dataiter)\n",
    "    concatenated = torch.cat((x0,x1),0)\n",
    "    if cuda.is_available():\n",
    "        output1 = model(Variable(x0).cuda())\n",
    "        output2 = model(Variable(x1).cuda())   \n",
    "    else:\n",
    "        output1 = model(Variable(x0))\n",
    "        output2 = model(Variable(x1))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f}'.format(euclidean_distance.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)",
   "language": "python",
   "name": "python37764bitbachelorthesisvenv02556f6d95bb441ca9c35a29550b23bd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}