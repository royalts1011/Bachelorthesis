{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import numpy as np\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "\n",
    "# DLBio and own scripts\n",
    "from DLBio.pytorch_helpers import get_device\n",
    "import transforms_data as td\n",
    "from helpers import cuda_conv\n",
    "import metrics as M\n",
    "import acquire_ear_dataset as a\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    DEVICE = get_device()\n",
    "    DATASET_DIR = '../dataset/'\n",
    "    AUTH_DATASET_DIR = '../auth_dataset/unknown-auth/'\n",
    "    MODEL_DIR = './models/model_MN_color.pt'\n",
    "    RESIZE_SMALL = False\n",
    "    DATABASE_FOLDER = './embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'mode' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9ac53c347ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpreprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms_siamese_verification\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESIZE_SMALL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mode' is not defined"
     ]
    }
   ],
   "source": [
    "model = torch.load(Config.MODEL_DIR, map_location=torch.device(Config.DEVICE))\n",
    "transformation = td.transforms_siamese_verification( td.get_resize(Config.RESIZE_SMALL) )\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(input_, preprocess):\n",
    "    #input_ = input_.convert(\"L\")\n",
    "    input_ = preprocess(input_)\n",
    "    input_ = input_.reshape(-1, td.get_resize(Config.RESIZE_SMALL)[0], td.get_resize(Config.RESIZE_SMALL)[1], 1)\n",
    "    input_ = input_.permute(3, 0, 1, 2)\n",
    "\n",
    "    if cuda.is_available():\n",
    "        return input_.type('torch.cuda.FloatTensor')\n",
    "    else:\n",
    "        return input_.type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(Config.DATASET_DIR + 'janna_qua/janna_qua003.png')\n",
    "# new_embedding = [model(Variable(pipeline(img,transformation))).cpu()]\n",
    "# test = np.array(new_embedding)\n",
    "\n",
    "# np.save('test.npy', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[tensor([[0.4768, 0.4880, 0.5734,  ..., 0.4703, 0.4180, 0.4802]],\n       requires_grad=True)]\n[tensor([[0.4768, 0.4880, 0.5734,  ..., 0.4703, 0.4180, 0.4802]],\n       grad_fn=<CopyBackwards>)]\n3.577686220523901e-05\n"
    }
   ],
   "source": [
    "# loaded_test = np.load('test.npy', allow_pickle=True)\n",
    "\n",
    "# print(loaded_test)\n",
    "# print(new_embedding)\n",
    "\n",
    "# value = F.pairwise_distance(loaded_test[0],new_embedding[0]).item()\n",
    "# print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_value = []\n",
    "result_label = []\n",
    "\n",
    "img = Image.open(Config.DATASET_DIR + 'janna_qua/janna_qua003.png')\n",
    "new_embedding = model(Variable(pipeline(img,transformation))).cpu()\n",
    "\n",
    "for label in os.listdir(Config.DATABASE_FOLDER):\n",
    "    loaded_embedding = np.load(Config.DATABASE_FOLDER+label, allow_pickle=True)\n",
    "    tmp = []    \n",
    "    for embedding in loaded_embedding:\n",
    "        dis = F.pairwise_distance(embedding,new_embedding)\n",
    "        tmp.append(dis.item())\n",
    "    result_value.append((min(tmp)))\n",
    "    result_label.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 :  janna_qua.npy :  3.571590059436858e-05\n2 :  tim_moe.npy :  0.09579116106033325\n3 :  clara_pau.npy :  0.09974295645952225\n4 :  collin_sch.npy :  0.11074963957071304\n5 :  marina_fri.npy :  0.1114228144288063\n6 :  clemens_blu.npy :  0.11395379155874252\n7 :  beatrix_mah.npy :  0.1154462918639183\n8 :  gregor_spi.npy :  0.11710232496261597\n9 :  mohammed_muh.npy :  0.11872290819883347\n10 :  konrad_von.npy :  0.11907429248094559\n"
    }
   ],
   "source": [
    "result_value, result_label = zip(*sorted(zip(result_value, result_label)))\n",
    "result_value = result_value[:10]\n",
    "result_label = result_label[:10]\n",
    "\n",
    "for idx, val in enumerate(result_label):\n",
    "    print(str(idx+1) + ' : ' + ' ' + val + ' : ' + ' ' + str(result_value[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594280526596",
   "display_name": "Python 3.7.8 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}