{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras import backend as K, models\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import relu\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "from os.path import join as join_\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 12124302983944637549\n, name: \"/device:XLA_CPU:0\"\ndevice_type: \"XLA_CPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 17606941499958503686\nphysical_device_desc: \"device: XLA_CPU device\"\n, name: \"/device:XLA_GPU:0\"\ndevice_type: \"XLA_GPU\"\nmemory_limit: 17179869184\nlocality {\n}\nincarnation: 17567937925089988474\nphysical_device_desc: \"device: XLA_GPU device\"\n]\nNum GPUs Available:  0\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dataset\n",
    "\n",
    "SET_DIR = '../AMI/'\n",
    "NUM_CLASSES = len(os.listdir('../AMI/'))\n",
    "\n",
    "# The shape which MobilenetV2 accepts as input and thus each image is resized to\n",
    "image_shape = (224, 224, 3)\n",
    "\n",
    "# NUM_EXAMPLES is the number of (A,P,N) triplets chosen for the same class (N belongs to a different class of course)\n",
    "NUM_EXAMPLES = 15\n",
    "\n",
    "# Triplets list will contain anchor(A), positive(P) and negative(N) triplets.\n",
    "triplets = []\n",
    "A = P = N = []\n",
    "\n",
    "# creating anchor, positive, negative triplets\n",
    "for _ in range(NUM_EXAMPLES):\n",
    "    for direc in os.listdir(SET_DIR):\n",
    "        dir_path = SET_DIR + direc\n",
    "        dir_contents = os.listdir(dir_path)\n",
    "        length = len(dir_contents)\n",
    "        \n",
    "        anchor = np.asarray(Image.open(join_(dir_path, dir_contents[np.random.randint(0, length)])))/255\n",
    "        anchor = cv2.resize(anchor, (180, 200)) \n",
    "        anchor = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in anchor.T]).T\n",
    "        \n",
    "        \n",
    "        positive = np.asarray(Image.open(join_(dir_path, dir_contents[np.random.randint(0, length)])))/255\n",
    "        positive = cv2.resize(positive, (180, 200)) \n",
    "        positive = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in positive.T]).T\n",
    "        \n",
    "        neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
    "        while neg_dir == direc: \n",
    "            neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
    "            \n",
    "        length_negative = len(os.listdir(SET_DIR + neg_dir))\n",
    "        negative = np.asarray(Image.open(\n",
    "                       join_(SET_DIR + neg_dir, \n",
    "                        os.listdir(SET_DIR + neg_dir)[np.random.randint(0, length_negative)])))/255\n",
    "        negative = cv2.resize(negative, (180, 200)) \n",
    "        negative = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in negative.T]).T\n",
    "        \n",
    "        # append triplet\n",
    "        triplets.append([anchor, positive, negative])\n",
    "        A.append(anchor)\n",
    "        P.append(positive)\n",
    "        N.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_function(vects, alpha=0.4):\n",
    "    x, y, z = vects\n",
    "    sum_square_xy = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    sum_square_xz = K.sum(K.square(x - z), axis=1, keepdims=True)\n",
    "    return K.sum(K.maximum(sum_square_xy - sum_square_xz + alpha, 0), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG():\n",
    "    image_input = Input(shape=(224, 224, 3))\n",
    "    model = MobileNetV2(input_tensor=image_input, weights='imagenet',include_top=True)\n",
    "    model.layers[-1].activation = relu\n",
    "    x_out = Dense(32)(model.layers[-1].output)\n",
    "    \n",
    "    new_model = Model(inputs=image_input, outputs=x_out)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    anchor = Input(shape=image_shape, name='anchor')\n",
    "    positive = Input(shape=image_shape, name='positive')\n",
    "    negative = Input(shape=image_shape, name='negative')\n",
    "    \n",
    "    # Passing each image through the VGG model\n",
    "    anchor_encoding = VGG()(anchor)\n",
    "    positive_encoding = VGG()(positive)\n",
    "    negative_encoding = VGG()(negative)\n",
    "\n",
    "    # Incorporating the triplet loss in the SimVecLayer\n",
    "    SimVecLayer = Lambda(triplet_function, output_shape=(1,))\n",
    "    \n",
    "    sim_APN = SimVecLayer([anchor_encoding, positive_encoding, negative_encoding])\n",
    "    \n",
    "    return Model(inputs=[anchor, positive, negative], outputs=sim_APN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nanchor (InputLayer)             (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\npositive (InputLayer)           (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nnegative (InputLayer)           (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nmodel_1 (Model)                 (None, 32)           3571016     anchor[0][0]                     \n__________________________________________________________________________________________________\nmodel_2 (Model)                 (None, 32)           3571016     positive[0][0]                   \n__________________________________________________________________________________________________\nmodel_3 (Model)                 (None, 32)           3571016     negative[0][0]                   \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n                                                                 model_2[1][0]                    \n                                                                 model_3[1][0]                    \n==================================================================================================\nTotal params: 10,713,048\nTrainable params: 10,610,712\nNon-trainable params: 102,336\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "# Compile the model with a loss and optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg height=\"255pt\" viewBox=\"0.00 0.00 422.50 191.00\" width=\"563pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-187 418.5,-187 418.5,4 -4,4\" stroke=\"none\"/>\n<!-- 139813400422224 -->\n<g class=\"node\" id=\"node1\"><title>139813400422224</title>\n<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 121,-182.5 121,-146.5 0,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"60.5\" y=\"-160.8\">anchor: InputLayer</text>\n</g>\n<!-- 139810582735760 -->\n<g class=\"node\" id=\"node4\"><title>139810582735760</title>\n<polygon fill=\"none\" points=\"14.5,-73.5 14.5,-109.5 122.5,-109.5 122.5,-73.5 14.5,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68.5\" y=\"-87.8\">model_1: Model</text>\n</g>\n<!-- 139813400422224&#45;&gt;139810582735760 -->\n<g class=\"edge\" id=\"edge1\"><title>139813400422224-&gt;139810582735760</title>\n<path d=\"M62.4366,-146.313C63.3406,-138.289 64.4383,-128.547 65.45,-119.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"68.9395,-119.858 66.5813,-109.529 61.9835,-119.074 68.9395,-119.858\" stroke=\"black\"/>\n</g>\n<!-- 139811233631056 -->\n<g class=\"node\" id=\"node2\"><title>139811233631056</title>\n<polygon fill=\"none\" points=\"139,-146.5 139,-182.5 266,-182.5 266,-146.5 139,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-160.8\">positive: InputLayer</text>\n</g>\n<!-- 139808514122000 -->\n<g class=\"node\" id=\"node5\"><title>139808514122000</title>\n<polygon fill=\"none\" points=\"148.5,-73.5 148.5,-109.5 256.5,-109.5 256.5,-73.5 148.5,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-87.8\">model_2: Model</text>\n</g>\n<!-- 139811233631056&#45;&gt;139808514122000 -->\n<g class=\"edge\" id=\"edge2\"><title>139811233631056-&gt;139808514122000</title>\n<path d=\"M202.5,-146.313C202.5,-138.289 202.5,-128.547 202.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"206,-119.529 202.5,-109.529 199,-119.529 206,-119.529\" stroke=\"black\"/>\n</g>\n<!-- 139811233629584 -->\n<g class=\"node\" id=\"node3\"><title>139811233629584</title>\n<polygon fill=\"none\" points=\"284.5,-146.5 284.5,-182.5 414.5,-182.5 414.5,-146.5 284.5,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-160.8\">negative: InputLayer</text>\n</g>\n<!-- 139808425251280 -->\n<g class=\"node\" id=\"node6\"><title>139808425251280</title>\n<polygon fill=\"none\" points=\"284.5,-73.5 284.5,-109.5 392.5,-109.5 392.5,-73.5 284.5,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5\" y=\"-87.8\">model_3: Model</text>\n</g>\n<!-- 139811233629584&#45;&gt;139808425251280 -->\n<g class=\"edge\" id=\"edge3\"><title>139811233629584-&gt;139808425251280</title>\n<path d=\"M346.837,-146.313C345.594,-138.289 344.085,-128.547 342.694,-119.569\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"346.128,-118.875 341.138,-109.529 339.211,-119.947 346.128,-118.875\" stroke=\"black\"/>\n</g>\n<!-- 139808415539280 -->\n<g class=\"node\" id=\"node7\"><title>139808415539280</title>\n<polygon fill=\"none\" points=\"141,-0.5 141,-36.5 264,-36.5 264,-0.5 141,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-14.8\">lambda_1: Lambda</text>\n</g>\n<!-- 139810582735760&#45;&gt;139808415539280 -->\n<g class=\"edge\" id=\"edge4\"><title>139810582735760-&gt;139808415539280</title>\n<path d=\"M100.596,-73.4937C118.777,-63.8606 141.715,-51.7068 161.223,-41.3705\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"163.004,-44.3882 170.201,-36.6136 159.726,-38.2028 163.004,-44.3882\" stroke=\"black\"/>\n</g>\n<!-- 139808514122000&#45;&gt;139808415539280 -->\n<g class=\"edge\" id=\"edge5\"><title>139808514122000-&gt;139808415539280</title>\n<path d=\"M202.5,-73.3129C202.5,-65.2895 202.5,-55.5475 202.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"206,-46.5288 202.5,-36.5288 199,-46.5289 206,-46.5288\" stroke=\"black\"/>\n</g>\n<!-- 139808425251280&#45;&gt;139808415539280 -->\n<g class=\"edge\" id=\"edge6\"><title>139808425251280-&gt;139808415539280</title>\n<path d=\"M305.925,-73.4937C287.472,-63.8606 264.192,-51.7068 244.393,-41.3705\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"245.765,-38.1389 235.281,-36.6136 242.526,-44.3442 245.765,-38.1389\" stroke=\"black\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (done over the intel cloud) \n",
    "model.fit(x = [A, P, N], y = np.zeros((len(A),1)),\n",
    "                  epochs=10, verbose=1,\n",
    "                  batch_size=32, validation_split=0.3,\n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-596723284980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenvfe65d2ae6af74790a8c3d2ed63037c92",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}