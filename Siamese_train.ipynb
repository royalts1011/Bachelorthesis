{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "# Importing the required modules\n",
    "from keras import backend as K, models\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications import VGG16\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import relu\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "from os.path import join as join_\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dataset\n",
    "\n",
    "SET_DIR = '../dataset_low_res/'\n",
    "NUM_CLASSES = len(os.listdir('../dataset_low_res/'))\n",
    "\n",
    "# The shape which MobilenetV2 accepts as input and thus each image is resized to\n",
    "image_shape = (224, 224, 3)\n",
    "\n",
    "# NUM_EXAMPLES is the number of (A,P,N) triplets chosen for the same class (N belongs to a different class of course)\n",
    "NUM_EXAMPLES = 15\n",
    "\n",
    "# Triplets list will contain anchor(A), positive(P) and negative(N) triplets.\n",
    "triplets = []\n",
    "A = P = N = []\n",
    "\n",
    "# creating anchor, positive, negative triplets\n",
    "for _ in range(NUM_EXAMPLES):\n",
    "    for direc in os.listdir(SET_DIR):\n",
    "        dir_path = SET_DIR + direc\n",
    "        dir_contents = os.listdir(dir_path)\n",
    "        length = len(dir_contents)\n",
    "        \n",
    "        anchor = np.asarray(Image.open(join_(dir_path, dir_contents[np.random.randint(0, length)])))/255\n",
    "        anchor = cv2.resize(anchor, (180, 200)) \n",
    "        anchor = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in anchor.T]).T\n",
    "        # anchor.shape = (200, 180, 3)\n",
    "        \n",
    "        \n",
    "        positive = np.asarray(Image.open(join_(dir_path, dir_contents[np.random.randint(0, length)])))/255\n",
    "        positive = cv2.resize(positive, (180, 200)) \n",
    "        positive = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in positive.T]).T\n",
    "        \n",
    "        neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
    "        while neg_dir == direc: \n",
    "            neg_dir = os.listdir(SET_DIR)[np.random.randint(NUM_CLASSES)]\n",
    "            \n",
    "        length_negative = len(os.listdir(SET_DIR + neg_dir))\n",
    "        negative = np.asarray(Image.open(\n",
    "                       join_(SET_DIR + neg_dir, \n",
    "                        os.listdir(SET_DIR + neg_dir)[np.random.randint(0, length_negative)])))/255\n",
    "        negative = cv2.resize(negative, (180, 200)) \n",
    "        negative = np.array([np.pad(a, ((22,22), (12,12)), 'constant') for a in negative.T]).T\n",
    "        \n",
    "        # append triplet\n",
    "        triplets.append([anchor, positive, negative])\n",
    "        A.append(anchor)\n",
    "        P.append(positive)\n",
    "        N.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_function(vects, alpha=0.05):\n",
    "    x, y, z = vects\n",
    "    sum_square_xy = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    sum_square_xz = K.sum(K.square(x - z), axis=1, keepdims=True)\n",
    "    return K.sum(K.maximum(sum_square_xy - sum_square_xz + alpha, 0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the MobilenetV2 model defined in keras.applications\n",
    "\n",
    "def MobnV2():\n",
    "    image_input = Input(shape=(224, 224, 3))\n",
    "    model = VGG16(input_tensor=image_input, weights='imagenet', include_top=True)\n",
    "    model.layers[-1].activation = relu\n",
    "    x_out = Dense(64)(model.layers[-1].output)\n",
    "    \n",
    "    new_model = Model(inputs=image_input, outputs=x_out)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    anchor = Input(shape=image_shape, name='anchor')\n",
    "    positive = Input(shape=image_shape, name='positive')\n",
    "    negative = Input(shape=image_shape, name='negative')\n",
    "    \n",
    "    # Passing each image through the MobilenetV2 model\n",
    "    req_model = MobnV2()\n",
    "    \n",
    "    # Pass the images through the same model\n",
    "    anchor_encoding = req_model(anchor)\n",
    "    positive_encoding = req_model(positive)\n",
    "    negative_encoding = req_model(negative)\n",
    "\n",
    "    # Incorporating the triplet loss in the SimVecLayer\n",
    "    SimVecLayer = Lambda(triplet_function, output_shape=(1,))\n",
    "    \n",
    "    sim_APN = SimVecLayer([anchor_encoding, positive_encoding, negative_encoding])\n",
    "    \n",
    "    return Model(inputs=[anchor, positive, negative], outputs=sim_APN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nanchor (InputLayer)             (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\npositive (InputLayer)           (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nnegative (InputLayer)           (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nmodel_1 (Model)                 (None, 64)           138421608   anchor[0][0]                     \n                                                                 positive[0][0]                   \n                                                                 negative[0][0]                   \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n                                                                 model_1[2][0]                    \n                                                                 model_1[3][0]                    \n==================================================================================================\nTotal params: 138,421,608\nTrainable params: 138,421,608\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "# Compile the model with a loss and optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<IPython.core.display.SVG object>",
      "image/svg+xml": "<svg height=\"255pt\" viewBox=\"0.00 0.00 422.50 191.00\" width=\"563pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33 1.33) rotate(0) translate(4 187)\">\n<title>G</title>\n<polygon fill=\"white\" points=\"-4,4 -4,-187 418.5,-187 418.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 5634282320 -->\n<g class=\"node\" id=\"node1\">\n<title>5634282320</title>\n<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 121,-182.5 121,-146.5 0,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"60.5\" y=\"-160.8\">anchor: InputLayer</text>\n</g>\n<!-- 5635786320 -->\n<g class=\"node\" id=\"node4\">\n<title>5635786320</title>\n<polygon fill=\"none\" points=\"148.5,-73.5 148.5,-109.5 256.5,-109.5 256.5,-73.5 148.5,-73.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-87.8\">model_1: Model</text>\n</g>\n<!-- 5634282320&#45;&gt;5635786320 -->\n<g class=\"edge\" id=\"edge1\">\n<title>5634282320-&gt;5635786320</title>\n<path d=\"M94.51,-146.49C113.95,-136.77 138.53,-124.49 159.32,-114.09\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"160.89,-117.22 168.27,-109.61 157.76,-110.96 160.89,-117.22\" stroke=\"black\"/>\n</g>\n<!-- 5634149776 -->\n<g class=\"node\" id=\"node2\">\n<title>5634149776</title>\n<polygon fill=\"none\" points=\"139,-146.5 139,-182.5 266,-182.5 266,-146.5 139,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-160.8\">positive: InputLayer</text>\n</g>\n<!-- 5634149776&#45;&gt;5635786320 -->\n<g class=\"edge\" id=\"edge2\">\n<title>5634149776-&gt;5635786320</title>\n<path d=\"M202.5,-146.31C202.5,-138.29 202.5,-128.55 202.5,-119.57\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"206,-119.53 202.5,-109.53 199,-119.53 206,-119.53\" stroke=\"black\"/>\n</g>\n<!-- 5634149264 -->\n<g class=\"node\" id=\"node3\">\n<title>5634149264</title>\n<polygon fill=\"none\" points=\"284.5,-146.5 284.5,-182.5 414.5,-182.5 414.5,-146.5 284.5,-146.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-160.8\">negative: InputLayer</text>\n</g>\n<!-- 5634149264&#45;&gt;5635786320 -->\n<g class=\"edge\" id=\"edge3\">\n<title>5634149264-&gt;5635786320</title>\n<path d=\"M314.29,-146.49C294.16,-136.77 268.73,-124.49 247.2,-114.09\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"248.46,-110.81 237.93,-109.61 245.41,-117.11 248.46,-110.81\" stroke=\"black\"/>\n</g>\n<!-- 5636001424 -->\n<g class=\"node\" id=\"node5\">\n<title>5636001424</title>\n<polygon fill=\"none\" points=\"141,-0.5 141,-36.5 264,-36.5 264,-0.5 141,-0.5\" stroke=\"black\"/>\n<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.5\" y=\"-14.8\">lambda_1: Lambda</text>\n</g>\n<!-- 5635786320&#45;&gt;5636001424 -->\n<g class=\"edge\" id=\"edge4\">\n<title>5635786320-&gt;5636001424</title>\n<path d=\"M202.5,-73.31C202.5,-65.29 202.5,-55.55 202.5,-46.57\" fill=\"none\" stroke=\"black\"/>\n<polygon fill=\"black\" points=\"206,-46.53 202.5,-36.53 199,-46.53 206,-46.53\" stroke=\"black\"/>\n</g>\n</g>\n</svg>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (done over the intel cloud) \n",
    "A, P, N = np.array(A), np.array(P), np.array(N)\n",
    "\n",
    "model.fit(x = [A, P, N], y = np.zeros((A.shape[0],1)),\n",
    "                  epochs=10, verbose=1,\n",
    "                  batch_size=32, validation_split=0.4,\n",
    "                  callbacks=[EarlyStopping(monitor='val_loss', patience=3)])\n",
    "\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenv02556f6d95bb441ca9c35a29550b23bd",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}