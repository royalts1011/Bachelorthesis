{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import transforms_data as td\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torch import cuda\n",
    "import acquire_ear_dataset as a\n",
    "import os\n",
    "import shutil\n",
    "from DLBio.pytorch_helpers import get_device\n",
    "\n",
    "\n",
    "\n",
    "CATEGORIES = [\"mila_wol\", \"falco_len\", \"jesse_kru\", \"konrad_von\", \"nils_loo\", \"johannes_boe\", \"johannes_wie\", \"sarah_feh\", \"janna_qua\", \"tim_moe\"]\n",
    "CATEGORIES.sort()\n",
    "AUTHORIZED = [\"falco_len\",\"konrad_von\"]\n",
    "RESIZE_Y = 150\n",
    "RESIZE_X = 100\n",
    "DATA_TEST_FOLDER = \"../auth_dataset/unknown-auth/*png\"\n",
    "DEVICE = get_device()\n",
    "\n",
    "model = torch.load('./class_sample/model.pt', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilder aufnehmen\n",
    "a.capture_ear_images(amount_pic=10, pic_per_stage=10, is_authentification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "files = glob.glob (DATA_TEST_FOLDER)\n",
    "files.sort()\n",
    "# declare function of transformation\n",
    "preprocess = td.transforms_valid_and_test((RESIZE_Y, RESIZE_X),[0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "for f in files:\n",
    "    image = Image.open(f)\n",
    "    image_transformed = preprocess(image)\n",
    "    image_transformed = image_transformed.reshape(-1, RESIZE_Y, RESIZE_X, 1)\n",
    "    image_transformed = image_transformed.permute(3, 0, 1, 2)\n",
    "    if cuda.is_available():\n",
    "        image_array.append(image_transformed.type('torch.cuda.FloatTensor'))\n",
    "    else:\n",
    "        image_array.append(image_transformed.type('torch.FloatTensor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = []\n",
    "summ_pred = np.zeros(1)\n",
    "for i in image_array:\n",
    "\twith torch.no_grad():\n",
    "\t\tpred = model(i)\n",
    "\t\tpred = torch.softmax(pred, 1)\n",
    "\t\tpred = pred.cpu().numpy()\n",
    "\t\tsumm_pred = summ_pred + pred\n",
    "\n",
    "\tclasses = np.argmax(pred, 1)\n",
    "\tall_classes.append(classes[0])\n",
    "\n",
    "\tpred = np.append(pred, classes)\n",
    "\tpred = np.append(pred, CATEGORIES[classes[0]])\t\n",
    "\tprint(pred, \"\\n\")\n",
    "print(all_classes)\n",
    "print(summ_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUMBER_AUTHORIZED = int(.3*len(image_array))\n",
    "authentification_dict = {CATEGORIES[i]:all_classes.count(i) for i in all_classes}\n",
    "print(authentification_dict) \n",
    "\n",
    "for a in authentification_dict:\n",
    "    if a in AUTHORIZED and summ_pred[0][CATEGORIES.index(a)]>= NUMBER_AUTHORIZED:\n",
    "        print(\"Access granted! Welcome \"  + a + \"!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Access denied\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('../auth_dataset/unknown-auth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenv02556f6d95bb441ca9c35a29550b23bd",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}