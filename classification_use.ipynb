{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import ds_ear\n",
    "import glob\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from DLBio import pt_training\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "from DLBio.pytorch_helpers import get_device, get_num_params\n",
    "from DLBio.helpers import check_mkdir\n",
    "from DLBio.pt_train_printer import Printer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "\n",
    "CATEGORIES = [\"Falco\",\"Konrad\"]\n",
    "RESIZE_Y = 150\n",
    "RESIZE_X = 100\n",
    "DATA_TEST_FOLDER = \"../test/*png\"\n",
    "\n",
    "\n",
    "def get_data(folder):\n",
    "    img_array = []\n",
    "    img_array_resized = []\n",
    "    files = glob.glob (folder)\n",
    "    for idx, f in zip(range(len(files)),files):\n",
    "        image = cv2.imread(f)\n",
    "        img_array.append (image)\n",
    "        img_array_resized.append(cv2.resize(img_array[idx],(RESIZE_Y,RESIZE_X)))\n",
    "    return np.asarray(img_array_resized)\n",
    "\n",
    "\n",
    "model = torch.load('./class_sample/model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "files = glob.glob (DATA_TEST_FOLDER)\n",
    "files.sort()\n",
    "for idx, f in zip(range(len(files)),files):\n",
    "    image = Image.open(f)\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((RESIZE_Y, RESIZE_X)),\n",
    "        torchvision.transforms.Lambda(lambda x: x.convert('RGB')),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.49139968, 0.48215841, 0.44653091],\n",
    "            [0.24703223, 0.24348513, 0.26158784]\n",
    "        )\n",
    "    ])\n",
    "    image_transformed = transform(image)\n",
    "    image_transformed = image_transformed.reshape(-1, RESIZE_Y, RESIZE_X, 1)\n",
    "    image_transformed = image_transformed.permute(3, 0, 1, 2)\n",
    "    image_array.append(image_transformed.type('torch.cuda.FloatTensor'))\n",
    "# image_transformed = image_transformed.type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_AUTHORIZED = int(.7*len(image_array))\n",
    "\n",
    "for i in image_array:\n",
    "\twith torch.no_grad():\n",
    "\t\tpred = model(i)\n",
    "\t\tpred = torch.softmax(pred, 1)\n",
    "\t\tpred = pred.cpu().numpy()\n",
    "\tclasses_ = np.argmax(pred, 1)\n",
    "\tprint(pred)\n",
    "\tprint(classes_)\n",
    "\tprint(CATEGORIES[classes_[0]], \"\\n\")\n",
    "# counts = np.bincount(classes_)\n",
    "# if np.max(counts) > NUMBER_AUTHORIZED:\n",
    "# \tprint(\"Welcome to your save room \" + CATEGORIES[np.argmax(counts)] + \"!\")\n",
    "# else: \n",
    "# \tprint(\"Authentification Failed! You got no acces rights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_AUTHORIZED = int(.7*len(data_tensor))\n",
    "with torch.no_grad():\n",
    "\tpred = model(data_tensor)\n",
    "\tpred = torch.softmax(pred, 1)\n",
    "\tpred = pred.cpu().numpy()\n",
    "\n",
    "classes_ = np.argmax(pred, 1)\n",
    "print(pred)\n",
    "print(classes_)\n",
    "counts = np.bincount(classes_)\n",
    "if np.max(counts) > NUMBER_AUTHORIZED:\n",
    "\tprint(\"Welcome to your save room \" + CATEGORIES[np.argmax(counts)] + \"!\")\n",
    "else: \n",
    "\tprint(\"Authentification Failed! You got no acces rights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(DATA_TEST_FOLDER)\n",
    "data_tensor = torch.from_numpy(data)\n",
    "data_tensor = data_tensor.permute(0, 3, 1, 2)\n",
    "data_tensor = data_tensor.type('torch.cuda.FloatTensor')\n",
    "#device = get_device()\n",
    "#print(device)\n",
    "#if device == cpu:\n",
    "#    data_tensor = data_tensor.type('torch.FloatTensor')\n",
    "#else:\n",
    "#    data_tensor = data_tensor.type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenvfe65d2ae6af74790a8c3d2ed63037c92",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}