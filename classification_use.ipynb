{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import ds_ear\n",
    "import glob\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from DLBio import pt_training\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "from DLBio.pytorch_helpers import get_device, get_num_params\n",
    "from DLBio.helpers import check_mkdir\n",
    "from DLBio.pt_train_printer import Printer\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "\n",
    "CATEGORIES = [\"Falco\",\"Konrad\"]\n",
    "RESIZE_Y = 150\n",
    "RESIZE_X = 100\n",
    "DATA_TEST_FOLDER = \"../test/*jpg\"\n",
    "\n",
    "\n",
    "def get_data(folder):\n",
    "    img_array = []\n",
    "    img_array_resized = []\n",
    "    files = glob.glob (folder)\n",
    "    for idx, f in zip(range(len(files)),files):\n",
    "        image = cv2.imread(f)\n",
    "        img_array.append (image)\n",
    "        img_array_resized.append(cv2.resize(img_array[idx],(RESIZE_Y,RESIZE_X)))\n",
    "    return np.asarray(img_array_resized)\n",
    "\n",
    "\n",
    "model = torch.load('./class_sample/model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "files = glob.glob (DATA_TEST_FOLDER)\n",
    "files.sort()\n",
    "for idx, f in zip(range(len(files)),files):\n",
    "    image = Image.open(f)\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((RESIZE_Y, RESIZE_X)),\n",
    "        torchvision.transforms.Lambda(lambda x: x.convert('RGB')),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "\n",
    "        torchvision.transforms.Normalize(\n",
    "            [0.49139968, 0.48215841, 0.44653091],\n",
    "            [0.24703223, 0.24348513, 0.26158784]\n",
    "        )\n",
    "    ])\n",
    "    image_transformed = transform(image)\n",
    "    image_transformed = image_transformed.reshape(-1, RESIZE_Y, RESIZE_X, 1)\n",
    "    image_transformed = image_transformed.permute(3, 0, 1, 2)\n",
    "    image_array.append(image_transformed.type('torch.cuda.FloatTensor'))\n",
    "# image_transformed = image_transformed.type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[2.08256868e-04 6.35882679e-05 4.91493056e-03 5.66407049e-04\n  1.92165317e-03 2.62933038e-03 4.10186732e-03 8.41381625e-05\n  5.00227034e-04 8.76283884e-01 4.84993029e-03 1.56702241e-04\n  5.29320957e-03 4.53771463e-05 4.71713338e-06 3.69879672e-06\n  1.14693925e-04 3.70703451e-02 4.34239373e-05 1.05507039e-04\n  4.79854862e-05 2.02506967e-03 2.70715100e-04 5.54245780e-04\n  1.97694717e-05 2.79728643e-04 6.42272353e-05 1.38018941e-05\n  8.83804842e-06 9.12864834e-06 9.96558461e-03 3.68705732e-05\n  9.05019639e-04 1.59055213e-04 6.02344342e-04 1.21887979e-05\n  5.08736230e-05 1.27988154e-04 2.06786615e-04 5.50897357e-06\n  2.69570978e-06 8.09037665e-05 2.49355780e-05 3.46133493e-05\n  6.85495991e-07 3.47839014e-05 3.79243465e-06 1.91493658e-04\n  9.67969572e-06 7.94715834e-06 1.27966189e-06 3.08079871e-05\n  1.12165171e-05 2.27567343e-05 6.60870428e-05 4.63404067e-05\n  6.70359659e-05 1.40984746e-04 9.53758956e-08 1.34202082e-06\n  9.57546290e-05 1.07142523e-05 1.29138889e-05 6.71334919e-06\n  2.19688773e-05 6.89503281e-07 3.12331074e-04 7.52370543e-05\n  3.86121043e-04 2.48286779e-05 1.59629475e-04 1.40389093e-05\n  2.82520591e-06 5.77536266e-05 1.10925102e-04 1.00190628e-05\n  1.65982550e-04 3.59649785e-05 6.52261951e-06 2.21596856e-05\n  3.21276184e-06 1.76602907e-06 1.65565166e-06 1.66131554e-06\n  1.28036016e-04 1.59025956e-02 5.51786525e-06 2.19404428e-05\n  3.11421427e-05 1.00801417e-05 3.26222435e-05 2.27491092e-03\n  1.06237436e-04 2.27872618e-02 1.99954502e-05 1.08020395e-04\n  1.64279857e-06 1.14024522e-04 4.53571329e-06 1.80304120e-03]]\n[9]\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e16d30d462c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCATEGORIES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# temp_img = torch.squeeze(i).cpu().permute(1,2,0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# plt.imshow( temp_img )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "NUMBER_AUTHORIZED = int(.7*len(image_array))\n",
    "\n",
    "for i in image_array:\n",
    "\twith torch.no_grad():\n",
    "\t\tpred = model(i)\n",
    "\t\tpred = torch.softmax(pred, 1)\n",
    "\t\tpred = pred.cpu().numpy()\n",
    "\tclasses_ = np.argmax(pred, 1)\n",
    "\tprint(pred)\n",
    "\tprint(classes_)\n",
    "\t# print(CATEGORIES[classes_[0]], \"\\n\")\n",
    "\ttemp_img = torch.squeeze(i).cpu().permute(1,2,0)\n",
    "\tplt.imshow( temp_img )\n",
    "# counts = np.bincount(classes_)\n",
    "# if np.max(counts) > NUMBER_AUTHORIZED:\n",
    "# \tprint(\"Welcome to your save room \" + CATEGORIES[np.argmax(counts)] + \"!\")\n",
    "# else: \n",
    "# \tprint(\"Authentification Failed! You got no acces rights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_AUTHORIZED = int(.7*len(data_tensor))\n",
    "with torch.no_grad():\n",
    "\tpred = model(data_tensor)\n",
    "\tpred = torch.softmax(pred, 1)\n",
    "\tpred = pred.cpu().numpy()\n",
    "\n",
    "classes_ = np.argmax(pred, 1)\n",
    "print(pred)\n",
    "print(classes_)\n",
    "counts = np.bincount(classes_)\n",
    "if np.max(counts) > NUMBER_AUTHORIZED:\n",
    "\tprint(\"Welcome to your save room \" + CATEGORIES[np.argmax(counts)] + \"!\")\n",
    "else: \n",
    "\tprint(\"Authentification Failed! You got no acces rights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(DATA_TEST_FOLDER)\n",
    "data_tensor = torch.from_numpy(data)\n",
    "data_tensor = data_tensor.permute(0, 3, 1, 2)\n",
    "data_tensor = data_tensor.type('torch.cuda.FloatTensor')\n",
    "#device = get_device()\n",
    "#print(device)\n",
    "#if device == cpu:\n",
    "#    data_tensor = data_tensor.type('torch.FloatTensor')\n",
    "#else:\n",
    "#    data_tensor = data_tensor.type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitearrecvenva72b417339b94420bd54db0855211b81",
   "display_name": "Python 3.7.7 64-bit ('earRec': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}