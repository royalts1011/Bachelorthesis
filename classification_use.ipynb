{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "CATEGORIES = [\"Konrad\", \"Falco\"]\n",
    "RESIZE_M = 150\n",
    "RESIZE_N = 100\n",
    "\n",
    "\n",
    "\n",
    "def get_data(file):\n",
    "    img_array = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    img_array_resized = cv2.resize(img_array,(RESIZE_M,RESIZE_N))\n",
    "    return img_array_resized.reshape(-1, RESIZE_M, RESIZE_N, 1)\n",
    "\n",
    "model = torch.load('/nfshome/lentzsch/Documents/Bachelorarbeit/Bachelorthesis/class_sample/model.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('/nfshome/lentzsch/Documents/Bachelorarbeit/Test/87_03.jpg')\n",
    "data_tensor = torch.from_numpy(data)\n",
    "data_tensor = data_tensor.permute(3, 0, 1, 2)\n",
    "data_tensor = data_tensor.type('torch.cuda.FloatTensor')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.03787524 0.00799194 0.00415512 0.0086069  0.00867832 0.01222535\n  0.00753807 0.01173239 0.01118797 0.01232294 0.01630513 0.00339146\n  0.01715949 0.00938326 0.00354201 0.01231655 0.01070243 0.02589811\n  0.00578906 0.01076487 0.00383922 0.02193992 0.00451431 0.00722737\n  0.0175337  0.00885013 0.00496216 0.0082654  0.00465333 0.00634938\n  0.00950257 0.00364388 0.01428516 0.05027529 0.01229513 0.00222091\n  0.00600326 0.00651646 0.01287579 0.00437717 0.00962772 0.02059837\n  0.00825229 0.00488951 0.00646023 0.00767304 0.00601724 0.00496616\n  0.0221217  0.00728452 0.0080738  0.0169499  0.01482013 0.00875552\n  0.00466089 0.01187763 0.01010035 0.00593443 0.00359235 0.00371961\n  0.01422636 0.00574379 0.00453984 0.00473677 0.00784235 0.00572652\n  0.00352739 0.00549835 0.00349867 0.01153255 0.0181451  0.0154596\n  0.00380119 0.00583726 0.00750893 0.01396428 0.01409017 0.01202962\n  0.00800238 0.00868687 0.01062758 0.00454277 0.00664148 0.00683614\n  0.02641461 0.01143537 0.00728644 0.00510202 0.01036329 0.0061263\n  0.00749872 0.01255327 0.00563704 0.00488369 0.01112529 0.00888507\n  0.00655463 0.00916818 0.00717148 0.02267614]]\n[33]\n"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\tpred = model(data_tensor)\n",
    "\tpred = torch.softmax(pred, 1)\n",
    "\tpred = pred.cpu().numpy()\n",
    "\n",
    "classes_ = np.argmax(pred, 1)\n",
    "print(pred)\n",
    "print(classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenvfe65d2ae6af74790a8c3d2ed63037c92",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}