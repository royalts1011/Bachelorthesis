{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import torch\n",
    "import numpy as np\n",
    "import transforms_data as td\n",
    "from PIL import Image\n",
    "import glob\n",
    "from torch import cuda\n",
    "import acquire_ear_dataset as a\n",
    "import os\n",
    "import shutil\n",
    "from DLBio.pytorch_helpers import get_device\n",
    "\n",
    "\n",
    "\n",
    "CATEGORIES = [\"falco_len\", \"jesse_kru\", \"konrad_von\", \"nils_loo\", \"johannes_boe\", \"johannes_wie\", \"sarah_feh\", \"janna_qua\", \"tim_moe\"]\n",
    "CATEGORIES.sort()\n",
    "AUTHORIZED = [\"falco_len\",\"konrad_von\"]\n",
    "RESIZE_Y = 150\n",
    "RESIZE_X = 100\n",
    "DATA_TEST_FOLDER = \"../auth_dataset/unknown-auth/*png\"\n",
    "DEVICE = get_device()\n",
    "\n",
    "model = torch.load('./class_sample/model.pt', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilder aufnehmen\n",
    "a.capture_ear_images(amount_pic=10, pic_per_stage=10, is_authentification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = []\n",
    "files = glob.glob (DATA_TEST_FOLDER)\n",
    "files.sort()\n",
    "# declare function of transformation\n",
    "preprocess = td.transforms_valid_and_test((RESIZE_Y, RESIZE_X),[0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "for f in files:\n",
    "    image = Image.open(f)\n",
    "    image_transformed = preprocess(image)\n",
    "    image_transformed = image_transformed.reshape(-1, RESIZE_Y, RESIZE_X, 1)\n",
    "    image_transformed = image_transformed.permute(3, 0, 1, 2)\n",
    "    if cuda.is_available():\n",
    "        image_array.append(image_transformed.type('torch.cuda.FloatTensor'))\n",
    "    else:\n",
    "        image_array.append(image_transformed.type('torch.FloatTensor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['0.08076418936252594' '0.07004870474338531' '0.08524050563573837'\n '0.21191458404064178' '0.02645527385175228' '0.423717737197876'\n '0.027206964790821075' '0.033973973244428635' '0.040678054094314575'\n '5.0' 'konrad_von'] \n\n['0.1117372065782547' '0.0633353665471077' '0.081693135201931'\n '0.19130420684814453' '0.027304014191031456' '0.4438782036304474'\n '0.03270541504025459' '0.021609796211123466' '0.02643265575170517' '5.0'\n 'konrad_von'] \n\n['0.14028088748455048' '0.021559104323387146' '0.05530431121587753'\n '0.2603743374347687' '0.022174619138240814' '0.44668373465538025'\n '0.025485936552286148' '0.02009640820324421' '0.00804058276116848' '5.0'\n 'konrad_von'] \n\n['0.17390774190425873' '0.07007075846195221' '0.08382807672023773'\n '0.16586485505104065' '0.03157679736614227' '0.362881600856781'\n '0.05234237015247345' '0.044171929359436035' '0.015355832874774933' '5.0'\n 'konrad_von'] \n\n['0.09942641109228134' '0.053986869752407074' '0.05682184174656868'\n '0.13338468968868256' '0.020356416702270508' '0.5548553466796875'\n '0.036962129175662994' '0.025655247271060944' '0.018551068380475044'\n '5.0' 'konrad_von'] \n\n['0.13078249990940094' '0.14823801815509796' '0.10245957225561142'\n '0.13523226976394653' '0.03918897360563278' '0.28155702352523804'\n '0.05454539880156517' '0.07893460988998413' '0.02906155399978161' '5.0'\n 'konrad_von'] \n\n['0.14744965732097626' '0.11930333077907562' '0.07244833558797836'\n '0.13287058472633362' '0.031088711693882942' '0.41097551584243774'\n '0.03513782471418381' '0.03245491534471512' '0.018271086737513542' '5.0'\n 'konrad_von'] \n\n['0.12927952408790588' '0.0858551487326622' '0.06726240366697311'\n '0.1713961362838745' '0.024848423898220062' '0.44577792286872864'\n '0.031434088945388794' '0.030041653662919998' '0.014104631729424' '5.0'\n 'konrad_von'] \n\n['0.12354349344968796' '0.08934333175420761' '0.08441153168678284'\n '0.1341075301170349' '0.026265788823366165' '0.43521830439567566'\n '0.04026397317647934' '0.04687945917248726' '0.019966572523117065' '5.0'\n 'konrad_von'] \n\n['0.18547846376895905' '0.048809438943862915' '0.0496068075299263'\n '0.22122865915298462' '0.039614979177713394' '0.378492146730423'\n '0.0380585677921772' '0.027842093259096146' '0.01086882222443819' '5.0'\n 'konrad_von'] \n\n[5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n[[1.33046258 0.77836257 0.74688902 1.76549035 0.2966865  4.19185004\n  0.38195517 0.36947259 0.20914336]]\n"
    }
   ],
   "source": [
    "all_classes = []\n",
    "summ_pred = np.empty(1)\n",
    "for i in image_array:\n",
    "\twith torch.no_grad():\n",
    "\t\tpred = model(i)\n",
    "\t\tpred = torch.softmax(pred, 1)\n",
    "\t\tpred = pred.cpu().numpy()\n",
    "\t\tsumm_pred = summ_pred + pred\n",
    "\n",
    "\tclasses = np.argmax(pred, 1)\n",
    "\tall_classes.append(classes[0])\n",
    "\n",
    "\tpred = np.append(pred, classes)\n",
    "\tpred = np.append(pred, CATEGORIES[classes[0]])\t\n",
    "\tprint(pred, \"\\n\")\n",
    "print(all_classes)\n",
    "print(summ_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'Falco': 7, 'Johannes': 1}\nAccess granted! Welcome Falco!\n"
    }
   ],
   "source": [
    "# Hier besser die Warscheinlichkeit 端ber alle Bilder ermitteln und dar端ber pr端fen.\n",
    "# Beispiel: Bei 5 Bilder muss die aufsummierte Wahrscheinlichkeit f端r eine Person >4 sein!!\n",
    "\n",
    "NUMBER_AUTHORIZED = int(.7*len(image_array))\n",
    "authentification_dict = {CATEGORIES[i]:all_classes.count(i) for i in all_classes}\n",
    "print(authentification_dict) \n",
    "\n",
    "for a in authentification_dict:\n",
    "    if a in AUTHORIZED and summ_pred[0][CATEGORIES.index(a)]>= NUMBER_AUTHORIZED:\n",
    "        print(\"Access granted! Welcome \"  + a + \"!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Access denied\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('../auth_dataset/unknown-auth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitbachelorthesisvenv02556f6d95bb441ca9c35a29550b23bd",
   "display_name": "Python 3.7.7 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}