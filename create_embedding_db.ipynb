{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import cuda\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "\n",
    "# DLBio and own scripts\n",
    "from DLBio.pytorch_helpers import get_device\n",
    "import ds_ear_siamese\n",
    "import transforms_data as td\n",
    "from helpers import cuda_conv\n",
    "import metrics as M\n",
    "from siamese_network_train import Training\n",
    "from ContrastiveLossFunction import ContrastiveLoss\n",
    "from NN_Siamese import SiameseNetwork\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    DEVICE = get_device()\n",
    "    DATASET_DIR = '../dataset/'\n",
    "    MODEL_DIR = './models/model_MN_allunfreezed.pt'\n",
    "    RESIZE_SMALL = False\n",
    "    DATABASE_FOLDER = './embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(Config.MODEL_DIR)\n",
    "model.to(Config.DEVICE)\n",
    "preprocess = td.transforms_siamese_verification( td.get_resize(Config.RESIZE_SMALL) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pipeline(input_, preprocess):\n",
    "    input_ = input_.convert(\"L\")\n",
    "    input_ = preprocess(input_)\n",
    "    input_ = input_.reshape(-1, td.get_resize(Config.RESIZE_SMALL)[0], td.get_resize(Config.RESIZE_SMALL)[1], 1)\n",
    "    input_ = input_.permute(3, 0, 1, 2)   \n",
    "    if cuda.is_available():\n",
    "        return input_.type('torch.cuda.FloatTensor')\n",
    "    else:\n",
    "        return input_.type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "test = []\n",
    "torch.cuda.synchronize()\n",
    "for label in os.listdir(Config.DATASET_DIR):\n",
    "    label_list.append(label)\n",
    "    image_list = []\n",
    "    for filename in glob.glob(Config.DATASET_DIR+label+'/*'): \n",
    "        img = Image.open(filename)\n",
    "        img_processed = image_pipeline(img,preprocess)\n",
    "        image_list.append(img_processed)\n",
    "    \n",
    "    embeddings = np.array([model(Variable(i)).cpu() for i in image_list])\n",
    "    \n",
    "    np.save(Config.DATABASE_FOLDER+label+'.npy', embeddings)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594212511715",
   "display_name": "Python 3.7.8 64-bit ('Bachelorthesis': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}